{
    "name": "dense_attention_bert",
    "model_config": {
        "vocab_size_or_config_json_file": 264,
        "d_model": 128,
        "d_state": 128,
        "num_hidden_layers": 6,
        "channels": 1,
        "bidirectional": true,
        "activation": "gelu",
        "postact": "glu",
        "dropout": 0.0,
        "tie_dropout": false,
        "transposed": false,
        "verbose": false,
        "measure":"diag-inv",
        "mode": "diag",
        "initializer_range": 0.02,
        "final_ln_type": "uncentered_ln",
        "pooler_no_dense": false,
        "pooler_function": "first",
        "classifier_bias": true,
        "pooler_act": "tanh",
        "lm_head_act": "legacy_gelu",
        "lm_head_ln_type": "uncentered_ln",
        "hidden_dropout_prob": 0

    },
    "data": {
        "training": {
            "input_files_path": "sentence_512/c4_en",
            "max_seq_length": 128,
            "total_samples": 1048576
        },
        "validation": {
            "input_file": "sentence_512/validation_data/part_000.txt",
            "max_seq_length": 128,
            "total_samples": 91500
        },
        "test": {}
    },
    "training": {
        "num_epochs": 1600,
        "lr_scheduler_params": {
            "warmup_ratio": 0.02,
            "warmup_degree": 1,
            "degree": 1,
            "one_cycle_steps": 140000
        },
        "lr_schedule": "cosine",
        "lr_offset": 0.0,
        "learning_rate": 5e-4,
        "weight_decay": 0.0,
        "num_workers": 4
    }
}